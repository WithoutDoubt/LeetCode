{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  inflating: /home/aistudio/work/test/test_99.wav  \r"
     ]
    }
   ],
   "source": [
    "!unzip /home/aistudio/data/data41960/dddd.zip -d /home/aistudio/work/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/work\n",
      "Sun Jul 19 21:32:38 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:06:00.0 Off |                    0 |\r\n",
      "| N/A   48C    P0    39W / 300W |      0MiB / 32480MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = \"/home/aistudio/work/\"\n",
    "os.chdir(path)\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import wave\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle as pkl\n",
    "import librosa\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "\n",
    "def extract_logmel(y, sr, size=3):\n",
    "    \"\"\"\n",
    "    extract log mel spectrogram feature\n",
    "    :param y: the input signal (audio time series)\n",
    "    :param sr: sample rate of 'y'\n",
    "    :param size: the length (seconds) of random crop from original audio, default as 3 seconds\n",
    "    :return: log-mel spectrogram feature\n",
    "    \"\"\"\n",
    "    # normalization\n",
    "    y = y.astype(np.float32)\n",
    "    normalization_factor = 1 / np.max(np.abs(y))\n",
    "    y = y * normalization_factor\n",
    "\n",
    "    # random crop\n",
    "    if len(y) <= size * sr:\n",
    "        new_y = np.zeros((size * sr+1, ))\n",
    "        new_y[:len(y)] = y\n",
    "        y = new_y\n",
    "\n",
    "    start = np.random.randint(0, len(y) - size * sr)\n",
    "    y = y[start: start + size * sr]\n",
    "\n",
    "    # extract log mel spectrogram #####\n",
    "    melspectrogram = librosa.feature.melspectrogram(\n",
    "        y=y, sr=sr, n_fft=2048, hop_length=1024, n_mels=60)\n",
    "    logmelspec = librosa.power_to_db(melspectrogram)\n",
    "\n",
    "    return logmelspec\n",
    "\n",
    "def get_wave_norm(file):\n",
    "    data, framerate = librosa.load(file, sr=22050)\n",
    "    return data, framerate\n",
    "\n",
    "\n",
    "LABELS = ['awake', 'diaper', 'hug', 'hungry', 'sleepy', 'uncomfortable']\n",
    "N_CLASS = len(LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/917 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awake train num: 160\n",
      "sleepy train num: 144\n",
      "hug train num: 160\n",
      "hungry train num: 160\n",
      "diaper train num: 134\n",
      "uncomfortable train num: 159\n",
      "done.\n",
      "917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 917/917 [06:43<00:00,  2.27it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\r\n",
    "import wave\r\n",
    "import librosa\r\n",
    "import numpy as np\r\n",
    "from tqdm import tqdm\r\n",
    "import pickle as pkl\r\n",
    "import librosa\r\n",
    "from sklearn.preprocessing import normalize\r\n",
    "\r\n",
    "#################################################   提取mfcc特征\r\n",
    "def extract_mfcc(y, sr, size=3):\r\n",
    "    \"\"\"\r\n",
    "    extract log mel spectrogram feature\r\n",
    "    :param y: the input signal (audio time series)\r\n",
    "    :param sr: sample rate of 'y'\r\n",
    "    :param size: the length (seconds) of random crop from original audio, default as 3 seconds\r\n",
    "    :return: log-mel spectrogram feature\r\n",
    "    \"\"\"\r\n",
    "    # normalization\r\n",
    "    y = y.astype(np.float32)\r\n",
    "    normalization_factor = 1 / np.max(np.abs(y))\r\n",
    "    y = y * normalization_factor\r\n",
    "\r\n",
    "    # random crop\r\n",
    "    if len(y) <= size * sr:\r\n",
    "        new_y = np.zeros((size * sr+1, ))\r\n",
    "        new_y[:len(y)] = y\r\n",
    "        y = new_y\r\n",
    "\r\n",
    "    start = np.random.randint(0, len(y) - size * sr)\r\n",
    "    y = y[start: start + size * sr]\r\n",
    "\r\n",
    "    # extract log mel spectrogram #####\r\n",
    "    mfcc = librosa.feature.mfcc(\r\n",
    "        y=y, sr = sr, hop_length = 1024\r\n",
    "    )\r\n",
    "    # melspectrogram = librosa.feature.melspectrogram(\r\n",
    "    #     y=y, sr=sr, n_fft=2048, hop_length=1024, n_mels=60)\r\n",
    "    # logmelspec = librosa.power_to_db(melspectrogram)\r\n",
    "\r\n",
    "    return mfcc\r\n",
    "\r\n",
    "def get_wave_norm(file):\r\n",
    "    data, framerate = librosa.load(file, sr=22050)\r\n",
    "    return data, framerate\r\n",
    "\r\n",
    "\r\n",
    "LABELS = ['awake', 'diaper', 'hug', 'hungry', 'sleepy', 'uncomfortable']\r\n",
    "N_CLASS = len(LABELS)\r\n",
    "\r\n",
    "# \r\n",
    "\r\n",
    "file_glob = []\r\n",
    "DATA_DIR = './train'\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "data = []\r\n",
    "\r\n",
    "file_glob = []\r\n",
    "\r\n",
    "for i, cls_fold in enumerate(os.listdir(DATA_DIR)):\r\n",
    "\r\n",
    "        cls_base = os.path.join(DATA_DIR, cls_fold)\r\n",
    "        lbl = cls_fold\r\n",
    "\r\n",
    "        files = os.listdir(cls_base)\r\n",
    "        print('{} train num:'.format(lbl), len(files))\r\n",
    "        for pt in files:\r\n",
    "            file_pt = os.path.join(cls_base, pt)\r\n",
    "            file_glob.append((file_pt, LABELS.index(lbl)))\r\n",
    "\r\n",
    "\r\n",
    "print('done.')\r\n",
    "print(len(file_glob))\r\n",
    "\r\n",
    "data = []\r\n",
    "\r\n",
    "for file, lbl in tqdm(file_glob):\r\n",
    "    try:\r\n",
    "        raw, sr = get_wave_norm(file)\r\n",
    "    except Exception as e:\r\n",
    "        print(e, file)\r\n",
    "    feature = extract_mfcc(y=raw, sr=sr, size=15) #########  3\r\n",
    "    y = np.zeros(N_CLASS)\r\n",
    "    y[lbl] = 1\r\n",
    "    data.append((feature, y))\r\n",
    "\r\n",
    "\r\n",
    "with open('./data_mfcc.pkl', 'wb') as f:\r\n",
    "    pkl.dump(data, f)\r\n",
    "\r\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/917 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awake train num: 160\n",
      "sleepy train num: 144\n",
      "hug train num: 160\n",
      "diaper train num: 134\n",
      "hungry train num: 160\n",
      "uncomfortable train num: 159\n",
      "done.\n",
      "917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 917/917 [06:40<00:00,  2.29it/s]\n"
     ]
    }
   ],
   "source": [
    "# \r\n",
    "\r\n",
    "file_glob = []\r\n",
    "DATA_DIR = './train'\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "data = []\r\n",
    "\r\n",
    "file_glob = []\r\n",
    "\r\n",
    "for i, cls_fold in enumerate(os.listdir(DATA_DIR)):\r\n",
    "\r\n",
    "        cls_base = os.path.join(DATA_DIR, cls_fold)\r\n",
    "        lbl = cls_fold\r\n",
    "\r\n",
    "        files = os.listdir(cls_base)\r\n",
    "        print('{} train num:'.format(lbl), len(files))\r\n",
    "        for pt in files:\r\n",
    "            file_pt = os.path.join(cls_base, pt)\r\n",
    "            file_glob.append((file_pt, LABELS.index(lbl)))\r\n",
    "\r\n",
    "\r\n",
    "print('done.')\r\n",
    "print(len(file_glob))\r\n",
    "\r\n",
    "data = []\r\n",
    "\r\n",
    "for file, lbl in tqdm(file_glob):\r\n",
    "    try:\r\n",
    "        raw, sr = get_wave_norm(file)\r\n",
    "    except Exception as e:\r\n",
    "        print(e, file)\r\n",
    "    feature = extract_logmel(y=raw, sr=sr, size=15) #########  3\r\n",
    "    y = np.zeros(N_CLASS)\r\n",
    "    y[lbl] = 1\r\n",
    "    data.append((feature, y))\r\n",
    "\r\n",
    "\r\n",
    "with open('./data.pkl', 'wb') as f:\r\n",
    "    pkl.dump(data, f)\r\n",
    "\r\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 323)\n"
     ]
    }
   ],
   "source": [
    "import os\r\n",
    "import wave\r\n",
    "import numpy as np\r\n",
    "import pickle as pkl\r\n",
    "\r\n",
    "train_x = []\r\n",
    "train_y = []\r\n",
    "\r\n",
    "LABELS = ['awake', 'diaper', 'hug', 'hungry', 'sleepy', 'uncomfortable']\r\n",
    "N_CLASS = len(LABELS)\r\n",
    "\r\n",
    "with open('./data_mfcc.pkl', 'rb') as f:\r\n",
    "    raw_data = pkl.load(f)\r\n",
    "\r\n",
    "np.random.seed(5)\r\n",
    "np.random.shuffle(raw_data)\r\n",
    "\r\n",
    "print(raw_data[0][0].shape)\r\n",
    "\r\n",
    "train_data = raw_data[:-50]\r\n",
    "valid_data = raw_data[-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "867\n",
      "50\n",
      "(20, 323)\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\r\n",
    "print(len(valid_data))\r\n",
    "print(train_data[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\r\n",
    "import paddle as paddle\r\n",
    "import paddle.fluid as fluid\r\n",
    "from PIL import Image\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import os\r\n",
    "import math\r\n",
    "\r\n",
    "def reader_createor(data):\r\n",
    "    def reader():\r\n",
    "        for i in  range(len(data)):\r\n",
    "            x = np.expand_dims(data[i][0].T, axis=0)\r\n",
    "            y = np.argmax(data[i][1])\r\n",
    "            if not np.random.randint(0, 2):\r\n",
    "                noise = np.random.rand(x.shape[0], x.shape[1], x.shape[2]) * 0.08 * x - 0.04\r\n",
    "                x += noise\r\n",
    "            yield x, y\r\n",
    "    return reader\r\n",
    "\r\n",
    "\r\n",
    "train_reader = paddle.batch(\r\n",
    "    paddle.reader.shuffle(\r\n",
    "        reader=reader_createor(train_data),buf_size=100\r\n",
    "    ), batch_size=64\r\n",
    ")\r\n",
    "\r\n",
    "valid_reader = paddle.batch(\r\n",
    "    paddle.reader.shuffle(\r\n",
    "        reader=reader_createor(valid_data),buf_size=100\r\n",
    "    ), batch_size=64\r\n",
    ")\r\n",
    "\r\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MyNet():\r\n",
    "    def __init__(self, is_train=True):\r\n",
    "\r\n",
    "        self.is_train = is_train\r\n",
    "        self.weight_decay = 1e-4\r\n",
    "\r\n",
    "    def net(self, input, class_dim):\r\n",
    "    \r\n",
    "        depth = [3, 3, 3, 3, 3]\r\n",
    "        num_filters = [16, 16, 32, 32, 64]\r\n",
    "\r\n",
    "        conv = self.conv_bn_layer(\r\n",
    "            input=input, num_filters=16, filter_size=3, act='elu')\r\n",
    "        conv = fluid.layers.pool2d(\r\n",
    "            input=conv,\r\n",
    "            pool_size=3,\r\n",
    "            pool_stride=2,\r\n",
    "            pool_padding=1,\r\n",
    "            pool_type='max')\r\n",
    "\r\n",
    "        for block in range(len(depth)):\r\n",
    "            for i in range(depth[block]):\r\n",
    "                conv = self.bottleneck_block(\r\n",
    "                    input=conv,\r\n",
    "                    num_filters=num_filters[block],\r\n",
    "                    stride=2 if i == 0 and block != 0 else 1)\r\n",
    "                conv = fluid.layers.batch_norm(input=conv)\r\n",
    "        print(conv.shape)\r\n",
    "        pool = fluid.layers.pool2d(\r\n",
    "            input=conv, pool_size=2, pool_type='max', global_pooling=False)\r\n",
    "       \r\n",
    "        pool = fluid.layers.conv2d(\r\n",
    "            input=pool, num_filters=32, filter_size=[3, 1], stride=[2, 1], act='elu')\r\n",
    "        print(pool.shape)\r\n",
    "        pool = fluid.layers.flatten(pool)\r\n",
    "        pool = fluid.layers.dropout(pool, dropout_prob=0.5)\r\n",
    "        net = fluid.layers.fc(input=pool,\r\n",
    "                              size=128,\r\n",
    "                              act=\"elu\"\r\n",
    "                              )\r\n",
    "        print(net.shape)\r\n",
    "        stdv = 1.0 / math.sqrt(pool.shape[1] * 1.0)\r\n",
    "        out = fluid.layers.fc(input=net,\r\n",
    "                              size=class_dim,\r\n",
    "                              act=\"softmax\",\r\n",
    "                              param_attr=fluid.param_attr.ParamAttr(\r\n",
    "                                  initializer=fluid.initializer.Uniform(-stdv,\r\n",
    "                                                                        stdv),\r\n",
    "                                  regularizer=fluid.regularizer.L2Decay(self.weight_decay))\r\n",
    "                              )\r\n",
    "        return out\r\n",
    "\r\n",
    "    def conv_bn_layer(self,\r\n",
    "                      input,\r\n",
    "                      num_filters,\r\n",
    "                      filter_size,\r\n",
    "                      stride=1,\r\n",
    "                      groups=1,\r\n",
    "                      act=None,\r\n",
    "                      bn_init_value=1.0):\r\n",
    "        conv = fluid.layers.conv2d(\r\n",
    "            input=input,\r\n",
    "            num_filters=num_filters,\r\n",
    "            filter_size=filter_size,\r\n",
    "            stride=stride,\r\n",
    "            padding=(filter_size - 1) // 2,\r\n",
    "            groups=groups,\r\n",
    "            act=None,\r\n",
    "            bias_attr=False,\r\n",
    "            param_attr=fluid.ParamAttr(regularizer=fluid.regularizer.L2Decay(self.weight_decay)))\r\n",
    "        return fluid.layers.batch_norm(\r\n",
    "                input=conv, act=act, is_test=not self.is_train,\r\n",
    "                param_attr=fluid.ParamAttr(\r\n",
    "                    initializer=fluid.initializer.Constant(bn_init_value),\r\n",
    "                    regularizer=None))\r\n",
    "\r\n",
    "    def shortcut(self, input, ch_out, stride):\r\n",
    "        ch_in = input.shape[1]\r\n",
    "        if ch_in != ch_out or stride != 1:\r\n",
    "            return self.conv_bn_layer(input, ch_out, 1, stride)\r\n",
    "        else:\r\n",
    "            return input\r\n",
    "\r\n",
    "    def bottleneck_block(self, input, num_filters, stride):\r\n",
    "        conv0 = self.conv_bn_layer(\r\n",
    "            input=input, num_filters=num_filters, filter_size=1, act='relu')\r\n",
    "        conv1 = self.conv_bn_layer(\r\n",
    "            input=conv0,\r\n",
    "            num_filters=num_filters,\r\n",
    "            filter_size=3,\r\n",
    "            stride=stride,\r\n",
    "            act='relu')\r\n",
    "        conv2 = self.conv_bn_layer(\r\n",
    "            input=conv1, num_filters=num_filters * 4, filter_size=1, act=None, bn_init_value=0.0)\r\n",
    "\r\n",
    "        short = self.shortcut(input, num_filters * 4, stride)\r\n",
    "\r\n",
    "        return fluid.layers.elementwise_add(x=short, y=conv2, act='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义输入输出层\r\n",
    "image = fluid.layers.data(name='image', shape=[1, 323, 20], dtype='float32')#单通道，28*28像素值\r\n",
    "label = fluid.layers.data(name='label', shape=[1], dtype='int64')          #图片标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-1, 256, 11, 1)\n"
     ]
    },
    {
     "ename": "EnforceNotMet",
     "evalue": "\n\n--------------------------------------------\nC++ Call Stacks (More useful to developers):\n--------------------------------------------\n0   std::string paddle::platform::GetTraceBackString<std::string const&>(std::string const&, char const*, int)\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int)\n2   paddle::operators::PoolOutputSize(int, int, int, int, int, bool)\n3   paddle::operators::PoolOp::InferShape(paddle::framework::InferShapeContext*) const\n4   paddle::framework::OpDesc::InferShape(paddle::framework::BlockDesc const&) const\n\n------------------------------------------\nPython Call Stacks (More useful to users):\n------------------------------------------\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 2525, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/nn.py\", line 1887, in pool2d\n    \"data_format\": data_format,\n  File \"<ipython-input-5-78ff70c74dd6>\", line 30, in net\n    input=conv, pool_size=2, pool_type='max', global_pooling=False)\n  File \"<ipython-input-13-cae3d2c1fb08>\", line 3, in <module>\n    out = model.net(input=image, class_dim=N_CLASS)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3265, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3183, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3018, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2843, in _run_cell\n    return runner(coro)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2817, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/asyncio/base_events.py\", line 1771, in _run_once\n    handle._run()\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/asyncio/base_events.py\", line 534, in run_forever\n    self._run_once()\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n\n----------------------\nError Message Summary:\n----------------------\nError: ShapeError: the output size must be greater than 0. But received: output_size = 0 due to the settings of input_size(1), padding(0,0), k_size(2) and stride(1). Please check again!\n  [Hint: Expected output_size > 0, but received output_size:0 <= 0:0.] at (/paddle/paddle/fluid/operators/pool_op.cc:44)\n  [operator < pool2d > error]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEnforceNotMet\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-cae3d2c1fb08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 获取分类器\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_CLASS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 获取损失函数和准确率函数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-78ff70c74dd6>\u001b[0m in \u001b[0;36mnet\u001b[0;34m(self, input, class_dim)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         pool = fluid.layers.pool2d(\n\u001b[0;32m---> 30\u001b[0;31m             input=conv, pool_size=2, pool_type='max', global_pooling=False)\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         pool = fluid.layers.conv2d(\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/nn.py\u001b[0m in \u001b[0;36mpool2d\u001b[0;34m(input, pool_size, pool_type, pool_stride, pool_padding, global_pooling, use_cudnn, ceil_mode, name, exclusive, data_format)\u001b[0m\n\u001b[1;32m   1885\u001b[0m             \u001b[0;34m\"use_mkldnn\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1886\u001b[0m             \u001b[0;34m\"exclusive\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mexclusive\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1887\u001b[0;31m             \u001b[0;34m\"data_format\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1888\u001b[0m         })\n\u001b[1;32m   1889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layer_helper.py\u001b[0m in \u001b[0;36mappend_op\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mappend_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain_program\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmultiple_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_param_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py\u001b[0m in \u001b[0;36mappend_op\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2523\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inputs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2524\u001b[0m                 \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"outputs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2525\u001b[0;31m                 attrs=kwargs.get(\"attrs\", None))\n\u001b[0m\u001b[1;32m   2526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2527\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1878\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_var_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_has_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEnforceNotMet\u001b[0m: \n\n--------------------------------------------\nC++ Call Stacks (More useful to developers):\n--------------------------------------------\n0   std::string paddle::platform::GetTraceBackString<std::string const&>(std::string const&, char const*, int)\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int)\n2   paddle::operators::PoolOutputSize(int, int, int, int, int, bool)\n3   paddle::operators::PoolOp::InferShape(paddle::framework::InferShapeContext*) const\n4   paddle::framework::OpDesc::InferShape(paddle::framework::BlockDesc const&) const\n\n------------------------------------------\nPython Call Stacks (More useful to users):\n------------------------------------------\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 2525, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/nn.py\", line 1887, in pool2d\n    \"data_format\": data_format,\n  File \"<ipython-input-5-78ff70c74dd6>\", line 30, in net\n    input=conv, pool_size=2, pool_type='max', global_pooling=False)\n  File \"<ipython-input-13-cae3d2c1fb08>\", line 3, in <module>\n    out = model.net(input=image, class_dim=N_CLASS)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3265, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3183, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3018, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2843, in _run_cell\n    return runner(coro)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2817, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/asyncio/base_events.py\", line 1771, in _run_once\n    handle._run()\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/asyncio/base_events.py\", line 534, in run_forever\n    self._run_once()\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n\n----------------------\nError Message Summary:\n----------------------\nError: ShapeError: the output size must be greater than 0. But received: output_size = 0 due to the settings of input_size(1), padding(0,0), k_size(2) and stride(1). Please check again!\n  [Hint: Expected output_size > 0, but received output_size:0 <= 0:0.] at (/paddle/paddle/fluid/operators/pool_op.cc:44)\n  [operator < pool2d > error]"
     ]
    }
   ],
   "source": [
    "# 获取分类器\r\n",
    "model = MyNet()\r\n",
    "out = model.net(input=image, class_dim=N_CLASS)\r\n",
    "\r\n",
    "# 获取损失函数和准确率函数\r\n",
    "cost = fluid.layers.cross_entropy(input=out, label=label) \r\n",
    "avg_cost = fluid.layers.mean(cost)\r\n",
    "acc = fluid.layers.accuracy(input=out, label=label)\r\n",
    "\r\n",
    "# 定义优化方法\r\n",
    "optimizer = fluid.optimizer.AdamOptimizer(learning_rate=2e-4)   #使用Adam算法进行优化\r\n",
    "opts = optimizer.minimize(avg_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义一个使用CPU的解析器\r\n",
    "model_save_dir = \"/home/aistudio/work/mfcc.inference.model\"\r\n",
    "\r\n",
    "place = fluid.CUDAPlace(0)\r\n",
    "exe = fluid.Executor(place)\r\n",
    "exe.run(fluid.default_startup_program())\r\n",
    "# fluid.io.load_params(executor=exe, dirname=model_save_dir,\r\n",
    "#                     main_program=None)\r\n",
    "feeder = fluid.DataFeeder(place=place, feed_list=[image, label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def draw_train_process(title,iters,costs,accs,label_cost,lable_acc):\r\n",
    "    plt.title(title, fontsize=24)\r\n",
    "    plt.xlabel(\"iter\", fontsize=20)\r\n",
    "    plt.ylabel(\"cost/acc\", fontsize=20)\r\n",
    "    plt.plot(iters, costs,color='red',label=label_cost) \r\n",
    "    plt.plot(iters, accs,color='green',label=lable_acc) \r\n",
    "    plt.legend()\r\n",
    "    plt.grid()\r\n",
    "    plt.show()\r\n",
    "    \r\n",
    "all_train_iter=0\r\n",
    "all_train_iters=[]\r\n",
    "all_train_costs=[]\r\n",
    "all_train_accs=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py:782: UserWarning: The following exception is not an EOF exception.\n",
      "  \"The following exception is not an EOF exception.\")\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "EnforceNotMet",
     "evalue": "\n\n--------------------------------------------\nC++ Call Stacks (More useful to developers):\n--------------------------------------------\n0   std::string paddle::platform::GetTraceBackString<std::string const&>(std::string const&, char const*, int)\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int)\n2   paddle::operators::PoolOutputSize(int, int, int, int, int, bool)\n3   paddle::operators::PoolOp::InferShape(paddle::framework::InferShapeContext*) const\n4   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&, paddle::framework::RuntimeContext*) const\n5   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&) const\n6   paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, paddle::platform::Place const&)\n7   paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool)\n8   paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, std::vector<std::string, std::allocator<std::string> > const&, bool, bool)\n\n------------------------------------------\nPython Call Stacks (More useful to users):\n------------------------------------------\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 2525, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/nn.py\", line 1887, in pool2d\n    \"data_format\": data_format,\n  File \"<ipython-input-7-78ff70c74dd6>\", line 30, in net\n    input=conv, pool_size=2, pool_type='max', global_pooling=False)\n  File \"<ipython-input-9-cae3d2c1fb08>\", line 3, in <module>\n    out = model.net(input=image, class_dim=N_CLASS)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3265, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3183, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3018, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2843, in _run_cell\n    return runner(coro)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2817, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/asyncio/base_events.py\", line 1771, in _run_once\n    handle._run()\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/asyncio/base_events.py\", line 534, in run_forever\n    self._run_once()\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n\n----------------------\nError Message Summary:\n----------------------\nError: ShapeError: the output size must be greater than 0. But received: output_size = 0 due to the settings of input_size(1), padding(0,0), k_size(2) and stride(1). Please check again!\n  [Hint: Expected output_size > 0, but received output_size:0 <= 0:0.] at (/paddle/paddle/fluid/operators/pool_op.cc:44)\n  [operator < pool2d > error]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEnforceNotMet\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-c42ddd81f56c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         train_cost, train_acc = exe.run(program=fluid.default_main_program(),#运行主程序\n\u001b[1;32m      9\u001b[0m                                         \u001b[0mfeed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeeder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m              \u001b[0;31m#给模型喂入数据\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                                         fetch_list=[avg_cost, acc])          #fetch 误差、准确率  \n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mall_train_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_train_iter\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, program, feed, fetch_list, feed_var_name, fetch_var_name, scope, return_numpy, use_program_cache)\u001b[0m\n\u001b[1;32m    781\u001b[0m                 warnings.warn(\n\u001b[1;32m    782\u001b[0m                     \"The following exception is not an EOF exception.\")\n\u001b[0;32m--> 783\u001b[0;31m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m     def _run_impl(self, program, feed, fetch_list, feed_var_name,\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, program, feed, fetch_list, feed_var_name, fetch_var_name, scope, return_numpy, use_program_cache)\u001b[0m\n\u001b[1;32m    776\u001b[0m                 \u001b[0mscope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m                 \u001b[0mreturn_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_numpy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m                 use_program_cache=use_program_cache)\n\u001b[0m\u001b[1;32m    779\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEOFException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py\u001b[0m in \u001b[0;36m_run_impl\u001b[0;34m(self, program, feed, fetch_list, feed_var_name, fetch_var_name, scope, return_numpy, use_program_cache)\u001b[0m\n\u001b[1;32m    829\u001b[0m                 \u001b[0mscope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m                 \u001b[0mreturn_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_numpy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m                 use_program_cache=use_program_cache)\n\u001b[0m\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m         \u001b[0mprogram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py\u001b[0m in \u001b[0;36m_run_program\u001b[0;34m(self, program, feed, fetch_list, feed_var_name, fetch_var_name, scope, return_numpy, use_program_cache)\u001b[0m\n\u001b[1;32m    903\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0muse_program_cache\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m             self._default_executor.run(program.desc, scope, 0, True, True,\n\u001b[0;32m--> 905\u001b[0;31m                                        fetch_var_name)\n\u001b[0m\u001b[1;32m    906\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m             self._default_executor.run_prepared_ctx(ctx, scope, False, False,\n",
      "\u001b[0;31mEnforceNotMet\u001b[0m: \n\n--------------------------------------------\nC++ Call Stacks (More useful to developers):\n--------------------------------------------\n0   std::string paddle::platform::GetTraceBackString<std::string const&>(std::string const&, char const*, int)\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int)\n2   paddle::operators::PoolOutputSize(int, int, int, int, int, bool)\n3   paddle::operators::PoolOp::InferShape(paddle::framework::InferShapeContext*) const\n4   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&, paddle::framework::RuntimeContext*) const\n5   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&) const\n6   paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, paddle::platform::Place const&)\n7   paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool)\n8   paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, std::vector<std::string, std::allocator<std::string> > const&, bool, bool)\n\n------------------------------------------\nPython Call Stacks (More useful to users):\n------------------------------------------\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 2525, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/nn.py\", line 1887, in pool2d\n    \"data_format\": data_format,\n  File \"<ipython-input-7-78ff70c74dd6>\", line 30, in net\n    input=conv, pool_size=2, pool_type='max', global_pooling=False)\n  File \"<ipython-input-9-cae3d2c1fb08>\", line 3, in <module>\n    out = model.net(input=image, class_dim=N_CLASS)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3265, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3183, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3018, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2843, in _run_cell\n    return runner(coro)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2817, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/asyncio/base_events.py\", line 1771, in _run_once\n    handle._run()\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/asyncio/base_events.py\", line 534, in run_forever\n    self._run_once()\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n\n----------------------\nError Message Summary:\n----------------------\nError: ShapeError: the output size must be greater than 0. But received: output_size = 0 due to the settings of input_size(1), padding(0,0), k_size(2) and stride(1). Please check again!\n  [Hint: Expected output_size > 0, but received output_size:0 <= 0:0.] at (/paddle/paddle/fluid/operators/pool_op.cc:44)\n  [operator < pool2d > error]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\r\n",
    "\r\n",
    "EPOCH_NUM=20  # 调参 训练轮数\r\n",
    "\r\n",
    "for pass_id in range(EPOCH_NUM):\r\n",
    "    # 进行训练\r\n",
    "    for data in tqdm(train_reader()):                         #遍历train_reader\r\n",
    "        train_cost, train_acc = exe.run(program=fluid.default_main_program(),#运行主程序\r\n",
    "                                        feed=feeder.feed(data),              #给模型喂入数据\r\n",
    "                                        fetch_list=[avg_cost, acc])          #fetch 误差、准确率  \r\n",
    "                                        \r\n",
    "        all_train_iter=all_train_iter+1\r\n",
    "        all_train_iters.append(all_train_iter)\r\n",
    "        all_train_costs.append(train_cost[0])\r\n",
    "        all_train_accs.append(train_acc[0])\r\n",
    "\r\n",
    "    print('Pass:%d, Cost:%0.5f, Accuracy:%0.5f' %\r\n",
    "                  (pass_id, np.mean(train_cost), np.mean(train_acc)))\r\n",
    "\r\n",
    "    # 进行测试\r\n",
    "    test_accs = []\r\n",
    "    test_costs = []\r\n",
    "    #每训练一轮 进行一次测试\r\n",
    "    for batch_id, data in enumerate(valid_reader()):                         #遍历test_reader\r\n",
    "        test_cost, test_acc = exe.run(program=fluid.default_main_program(), #执行训练程序\r\n",
    "                                      feed=feeder.feed(data),               #喂入数据\r\n",
    "                                      fetch_list=[avg_cost, acc])           #fetch 误差、准确率\r\n",
    "        test_accs.append(test_acc[0])                                       #每个batch的准确率\r\n",
    "        test_costs.append(test_cost[0])                                     #每个batch的误差\r\n",
    "\r\n",
    "    # 求测试结果的平均值\r\n",
    "    test_cost = (sum(test_costs) / len(test_costs))                         #每轮的平均误差\r\n",
    "    test_acc = (sum(test_accs) / len(test_accs))                            #每轮的平均准确率\r\n",
    "    print('Test:%d, Cost:%0.5f, Accuracy:%0.5f' % (pass_id, test_cost, test_acc))\r\n",
    "    \r\n",
    "    #保存模型\r\n",
    "    # 如果保存路径不存在就创建\r\n",
    "    if not os.path.exists(model_save_dir):\r\n",
    "        os.makedirs(model_save_dir)\r\n",
    "    print ('save models to %s' % (model_save_dir))\r\n",
    "    fluid.io.save_inference_model(model_save_dir,  #保存推理model的路径\r\n",
    "                                  ['image'],       #推理（inference）需要 feed 的数据\r\n",
    "                                  [out],       #保存推理（inference）结果的 Variables\r\n",
    "                                  exe)             #executor 保存 inference model\r\n",
    "draw_train_process(\"training\",all_train_iters,all_train_costs,all_train_accs,\"trainning cost\",\"trainning acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/228 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test num: 228\n",
      "done\n",
      "228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 228/228 [01:38<00:00,  2.31it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\r\n",
    "import wave\r\n",
    "import librosa\r\n",
    "import numpy as np \r\n",
    "from tqdm import tqdm\r\n",
    "import pickle as pkl \r\n",
    "from sklearn.preprocessing import normalize\r\n",
    "\r\n",
    "def extract_logmel (y, sr,size=3):\r\n",
    "    \"\"\"\r\n",
    "    extract log mel spectrogram feature\r\n",
    "    : param y: the input signal (audio time series)\r\n",
    "    : param sr: sample rate of 'y'\r\n",
    "    : param size: the length (seconds) of random crop from original audio, default as 3 seconds \r\n",
    "    \"\"\"\r\n",
    "    # normalization\r\n",
    "    y = y.astype(np.float32)\r\n",
    "    normalization_factor = 1 / np.max(np.abs(y))\r\n",
    "    y = y * normalization_factor\r\n",
    "\r\n",
    "    if len(y) <= size * sr:\r\n",
    "        new_y = np.zeros((size * sr + 1,))\r\n",
    "        new_y[:len(y)] = y\r\n",
    "        y = new_y\r\n",
    "\r\n",
    "    start = np.random.randint(0,len(y)-size*sr)  # 随机选取一个开始点\r\n",
    "    y = y[start : start + size * sr]               # 随机截取一下 y\r\n",
    "\r\n",
    "    melspectrogram = librosa.feature.melspectrogram(y = y,\r\n",
    "                                                    sr = sr,\r\n",
    "                                                    n_fft = 2048,\r\n",
    "                                                    hop_length = 1024,\r\n",
    "                                                    n_mels = 60)\r\n",
    "\r\n",
    "    logmelspec = librosa.power_to_db(melspectrogram)\r\n",
    "\r\n",
    "    return logmelspec\r\n",
    "\r\n",
    "def get_wave_norm(file):\r\n",
    "    data, framerate = librosa.load(file, sr = 22050)\r\n",
    "    return data,framerate\r\n",
    "\r\n",
    "LABELS = ['awake', 'diaper', 'hug', 'hungry', 'sleepy', 'uncomfortable']\r\n",
    "DATA_DIR = './train'\r\n",
    "DATA_DIR = './test'\r\n",
    "\r\n",
    "file_glob = []\r\n",
    "# data = []\r\n",
    "data = {}\r\n",
    "\r\n",
    "# for \r\n",
    "files = os.listdir(DATA_DIR)\r\n",
    "print('test num:' , len(files))\r\n",
    "for pt in files:\r\n",
    "    file_pt = os.path.join(DATA_DIR,pt)\r\n",
    "    file_glob.append(file_pt)                 #  \r\n",
    "\r\n",
    "print(\"done\")\r\n",
    "print(len(file_glob))\r\n",
    "\r\n",
    "for fileone in tqdm(file_glob):\r\n",
    "    try:\r\n",
    "        raw,sr = get_wave_norm(fileone)\r\n",
    "    except Exception as e:\r\n",
    "        print(e,fileone)\r\n",
    "    feature = extract_logmel(y = raw, sr = sr, size = 15)           # 15 s 是不对的\r\n",
    "    # y = np.zeros(len(LABELS))\r\n",
    "    # y[lbl] = 1\r\n",
    "    basename = os.path.basename(fileone)\r\n",
    "    data[basename] = feature\r\n",
    "    # data.append((feature,y))\r\n",
    "\r\n",
    "with open('./data_test.pkl', 'wb') as f:\r\n",
    "    pkl.dump(data,f)\r\n",
    "\r\n",
    "del data\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "test_x = []\r\n",
    "test_y = []\r\n",
    "\r\n",
    "with open ('./data_test.pkl','rb') as f:\r\n",
    "    raw_data = pkl.load(f)\r\n",
    "\r\n",
    "# print(raw_data[0][0].shape)\r\n",
    "\r\n",
    "test_data = raw_data\r\n",
    "\r\n",
    "print (len(test_data))\r\n",
    "print (type(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "infer_exe = fluid.Executor(place)\r\n",
    "#声明一个新的作用域\r\n",
    "inference_scope = fluid.core.Scope()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 228/228 [00:06<00:00, 33.86it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\r\n",
    "import wave\r\n",
    "import numpy as np\r\n",
    "import pickle as pkl\r\n",
    "\r\n",
    "from tqdm import tqdm\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "LABELS = ['awake', 'diaper', 'hug', 'hungry', 'sleepy', 'uncomfortable']\r\n",
    "N_CLASS = len(LABELS)\r\n",
    "\r\n",
    "with open('./data_test.pkl', 'rb') as f:\r\n",
    "    raw_data = pkl.load(f)\r\n",
    "\r\n",
    "feeder = fluid.DataFeeder(place=place, feed_list=[image])\r\n",
    "\r\n",
    "result = {'id': [], 'label': []}\r\n",
    "\r\n",
    "# model_save_dir = \"/home/aistudio/data/hand.inference.model\"\r\n",
    "#运行时中的所有变量都将分配给新的scope\r\n",
    "with fluid.scope_guard(inference_scope):\r\n",
    "    #获取训练好的模型\r\n",
    "    #从指定目录中加载模型\r\n",
    "    [inference_program,                                            #推理Program\r\n",
    "     feed_target_names,                                            #是一个str列表，它包含需要在推理 Program 中提供数据的变量的名称。 \r\n",
    "     fetch_targets] = fluid.io.load_inference_model(model_save_dir,#fetch_targets：是一个列表，从中我们可以得到推断结果。model_save_dir：模型保存的路径\r\n",
    "                                                    infer_exe)     #infer_exe: 运行 inference model的 executor    \r\n",
    "\r\n",
    "    for key, value in tqdm(raw_data.items()):\r\n",
    "    # for key, value in tqdm(raw_data):    \r\n",
    "        \r\n",
    "        # x = np.expand_dims(np.array(value), axis=1)\r\n",
    "        x = np.expand_dims(np.array(value).T,axis = 0)\r\n",
    "        x = np.expand_dims(x,axis = 0)\r\n",
    "        \r\n",
    "        y = infer_exe.run(program=inference_program,         #运行推测程序\r\n",
    "                   feed={feed_target_names[0]: x},           #喂入要预测的img\r\n",
    "                   fetch_list=fetch_targets)[0]                   #得到推测结果,  \r\n",
    "        if len(y) == 0:\r\n",
    "            print(key)\r\n",
    "        else:\r\n",
    "            y = np.mean(y, axis=0)\r\n",
    "            y = np.argmax(y)\r\n",
    "            pred = LABELS[y]\r\n",
    "        key = os.path.basename(key)\r\n",
    "        result['id'].append(key)\r\n",
    "        result['label'].append(pred)\r\n",
    "\r\n",
    "result = pd.DataFrame(result)\r\n",
    "result.to_csv('./submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 1.7.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
